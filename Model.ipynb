{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model MK1  ( Checking Pre-Treined VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3), pooling=None)\n",
    "# weights='imagenet'\n",
    "# input_shape=(224,224,3)\n",
    "# classes=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "img = load_img('/home/rodrigo/Batch/159/pngs/CT11.png')\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(img)\n",
    "print(image.shape)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gong (16.88%)\n"
     ]
    }
   ],
   "source": [
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model MK2 ( Remove Classification Layers from VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add our own fully connected layers for the final classification\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3), pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "#flattentit\n",
    "x = Flatten()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "#another fully-connected layer\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(1, kernel_initializer='normal', activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#now we can start to fine-tune the model\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Merged Label File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path = '/home/rodrigo/Projects/TCC/'\n",
    "# file = 'labels2.csv'\n",
    "# labels = np.loadtxt(open(path + file, \"rb\"), delimiter=\",\", skiprows=1)\n",
    "# exams = labels[:, 0]\n",
    "# ich = [ int(x/2) for x in np.sum(labels[:,1:4], axis=1) ]\n",
    "# iph = [ int(x/2) for x in np.sum(labels[:,4:7], axis=1)]\n",
    "# ivh = [ int(x/2) for x in np.sum(labels[:,7:10], axis=1)]\n",
    "# sdh = [ int(x/2) for x in np.sum(labels[:,10:13], axis=1)]\n",
    "# edh = [ int(x/2) for x in np.sum(labels[:,13:16], axis=1)]\n",
    "# sah = [ int(x/2) for x in np.sum(labels[:,16:19], axis=1)]\n",
    "# result = np.transpose(np.matrix([exams, ich, iph, ivh, sdh, edh, sah]))\n",
    "# np.savetxt(path + 'labels-merged.csv', result, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
